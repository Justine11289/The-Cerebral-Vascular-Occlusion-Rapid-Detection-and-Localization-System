{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0726-PointNet","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMa+k9MR0lP3msWHu8fgTrb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"utfPfkv9Xba3"},"outputs":[],"source":["!pip install trimesh\n","import os\n","import glob\n","import trimesh\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from matplotlib import pyplot as plt\n","tf.random.set_seed(1234)"]},{"cell_type":"code","source":["# Load dataset\n","DATA_DIR = tf.keras.utils.get_file(    # Downloads a file from a URL if it not already in the cache\n","    \"modelnet.zip\",\n","    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n","    extract=True, # True tries extracting the file as an Archive, like tar or zip\n",")\n","DATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")"],"metadata":{"id":"Id5islImYtsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 使用trimesh函式來讀取和可視化.off網格文件\n","mesh = trimesh.load(os.path.join(DATA_DIR, \"chair/train/chair_0001.off\"))\n","mesh.show()"],"metadata":{"id":"VOjAvpOOZFDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 將網格文件轉換為點雲\n","points = mesh.sample(2048)\n","fig = plt.figure(figsize=(5, 5))\n","ax = fig.add_subplot(111, projection=\"3d\")\n","ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n","ax.set_axis_off()\n","plt.show()"],"metadata":{"id":"f4AX_LYtajI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 解析ModelNet數據文件夾建立tf.data.Dataset()\n","def parse_dataset(num_points=2048):\n","  train_points = []\n","  train_labels = []\n","  test_points = []\n","  test_labels = []\n","  class_map = {}\n","  folders = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n","\n","  for i, folder in enumerate(folders):\n","    print(\"processing class: {}\".format(os.path.basename(folder)))\n","    # store folder name with ID so we can retrieve later\n","    class_map[i] = folder.split(\"/\")[-1]\n","    # gather all files\n","    train_files = glob.glob(os.path.join(folder, \"train/*\"))\n","    test_files = glob.glob(os.path.join(folder, \"test/*\"))\n","\n","    for f in train_files:\n","      train_points.append(trimesh.load(f).sample(num_points))\n","      train_labels.append(i)\n","\n","    for f in test_files:\n","      test_points.append(trimesh.load(f).sample(num_points))\n","      test_labels.append(i)\n","\n","  return(\n","      np.array(train_points),\n","      np.array(test_points),\n","      np.array(train_labels),\n","      np.array(test_labels),\n","      class_map,\n","  )"],"metadata":{"id":"bLuhtCWVaqdM","executionInfo":{"status":"ok","timestamp":1658915419892,"user_tz":-480,"elapsed":275,"user":{"displayName":"黃子庭","userId":"08688763290107689521"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 設置要採樣的點數和批量大小並解析數據集\n","NUM_POINTS = 2048\n","NUM_CLASSES = 10\n","BATCH_SIZE = 32\n","train_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(NUM_POINTS)"],"metadata":{"id":"t7mv5HIKarro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 增強函數來抖動和打亂訓練數據集\n","def augment(points, label):\n","  # jitter points\n","  points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n","  # shuffle points\n","  points = tf.random.shuffle(points)\n","  return points, label\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n","\n","train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\n","test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)"],"metadata":{"id":"R_xjaI1ha4wK","executionInfo":{"status":"ok","timestamp":1658915878339,"user_tz":-480,"elapsed":4738,"user":{"displayName":"黃子庭","userId":"08688763290107689521"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Build a model\n","def conv_bn(x, filters):\n","  x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n","  x = layers.BatchNormalization(momentum=0.0)(x)\n","  return layers.Activation(\"relu\")(x)\n","\n","def dense_bn(x, filters):\n","  x = layers.Dense(filters)(x)\n","  x = layers.BatchNormalization(momentum=0.0)(x)\n","  return layers.Activation(\"relu\")(x)\n","\n","class OrthogonalRegularizer(keras.regularizers.Regularizer):\n","  def __init__(self, num_features, l2reg=0.001):\n","    self.num_features = num_features\n","    self.l2reg = l2reg\n","    self.eye = tf.eye(num_features)\n","\n","  def __call__(self, x):\n","    x = tf.reshape(x, (-1, self.num_features, self.num_features))\n","    xxt = tf.tensordot(x, x, axes=(2, 2))\n","    xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n","    return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n","\n","def tnet(inputs, num_features):\n","  # Initalise bias as the indentity matrix\n","  bias = keras.initializers.Constant(np.eye(num_features).flatten())\n","  reg = OrthogonalRegularizer(num_features)\n","\n","  x = conv_bn(inputs, 32)\n","  x = conv_bn(x, 64)\n","  x = conv_bn(x, 512)\n","  x = layers.GlobalMaxPooling1D()(x)\n","  x = dense_bn(x, 256)\n","  x = dense_bn(x, 128)\n","  x = layers.Dense(\n","      num_features * num_features,\n","      kernel_initializer=\"zeros\",\n","      bias_initializer=bias,\n","      activity_regularizer=reg,\n","  )(x)\n","  feat_T = layers.Reshape((num_features, num_features))(x)\n","  # Apply affine transformation to input features\n","  return layers.Dot(axes=(2, 1))([inputs, feat_T])"],"metadata":{"id":"hwfqQdn7a8e1","executionInfo":{"status":"ok","timestamp":1658915999575,"user_tz":-480,"elapsed":411,"user":{"displayName":"黃子庭","userId":"08688763290107689521"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(NUM_POINTS, 3))\n","x = tnet(inputs, 3)\n","x = conv_bn(x, 32)\n","x = conv_bn(x, 32)\n","x = tnet(x, 32)\n","x = conv_bn(x, 32)\n","x = conv_bn(x, 64)\n","x = conv_bn(x, 512)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = dense_bn(x, 256)\n","x = layers.Dropout(0.3)(x)\n","x = dense_bn(x, 128)\n","x = layers.Dropout(0.3)(x)\n","\n","outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n","model.summary()"],"metadata":{"id":"wdAsJhd2fKQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train model\n","model.compile(\n","    loss=\"sparse_categorical_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n","    metrics=[\"sparse_categorical_accuracy\"],\n",")\n","model.fit(train_dataset, epochs=20, validation_data=test_dataset)"],"metadata":{"id":"3LP0bu4hhgSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize predictions\n","data = test_dataset.take(1)\n","points, labels = list(data)[0]\n","points = points[:8, ...]\n","labels = labels[:8, ...]\n","print(points)\n","\n","# run test data through model\n","preds = model.predict(points)\n","preds = tf.math.argmax(preds, -1)\n","\n","points = points.numpy()\n","\n","# plot points with predicted class and label\n","fig = plt.figure(figsize=(15, 10))\n","for i in range(8):\n","  ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n","  ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n","  ax.set_title(\n","      \"pred: {:}, label: {:}\".format(\n","          CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n","      )\n","  )\n","  ax.set_axis_off()\n","plt.show()"],"metadata":{"id":"T6FtvuvUhpAg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["點雲辨識"],"metadata":{"id":"6vdIV5wnjKA3"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","test_1 = np.load('/content/drive/My Drive/Project/Training/0726-point cloud/test1.npy')\n","test_2 = np.load('/content/drive/My Drive/Project/Training/0726-point cloud/test2.npy')\n","test_3 = np.load('/content/drive/My Drive/Project/Training/0726-point cloud/test3.npy')"],"metadata":{"id":"EV26mJ-dipFB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658916628205,"user_tz":-480,"elapsed":34203,"user":{"displayName":"黃子庭","userId":"08688763290107689521"}},"outputId":"fc489d2e-dba9-4108-f7cd-0f298ab85c2e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# test1.npy visualize predictions\n","tf1 = tf.convert_to_tensor(test_1)\n","points = tf1[:8, ...]\n","print(points)\n","\n","# run test data through model\n","preds = model.predict(points)\n","preds = tf.math.argmax(preds, -1)\n","\n","points = points.numpy()\n","\n","# plot points with predicted class and label\n","fig = plt.figure(figsize=(5, 5))\n","ax = fig.add_subplot(111, projection=\"3d\")\n","ax.scatter(points[0, :, 0], points[0, :, 1], points[0, :, 2])\n","ax.set_title(\n","    \"pred: {:}\".format(\n","        CLASS_MAP[preds[0].numpy()]\n","    )\n",")\n","ax.set_axis_off()\n","plt.show()"],"metadata":{"id":"F8spNb9sNkgK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test2.npy visualize predictions\n","tf2 = tf.convert_to_tensor(test_2)\n","points = tf2[:8, ...]\n","print(points)\n","\n","# run test data through model\n","preds = model.predict(points)\n","preds = tf.math.argmax(preds, -1)\n","\n","points = points.numpy()\n","\n","# plot points with predicted class and label\n","fig = plt.figure(figsize=(5, 5))\n","ax = fig.add_subplot(111, projection=\"3d\")\n","ax.scatter(points[0, :, 0], points[0, :, 1], points[0, :, 2])\n","ax.set_title(\n","    \"pred: {:}\".format(\n","        CLASS_MAP[preds[0].numpy()]\n","    )\n",")\n","ax.set_axis_off()\n","plt.show()"],"metadata":{"id":"cuPNNT5dKGpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test3.npy visualize predictions\n","tf3 = tf.convert_to_tensor(test_3)\n","points = tf3[:8, ...]\n","print(points)\n","\n","# run test data through model\n","preds = model.predict(points)\n","preds = tf.math.argmax(preds, -1)\n","\n","points = points.numpy()\n","\n","# plot points with predicted class and label\n","fig = plt.figure(figsize=(5, 5))\n","ax = fig.add_subplot(111, projection=\"3d\")\n","ax.scatter(points[0, :, 0], points[0, :, 1], points[0, :, 2])\n","ax.set_title(\n","    \"pred: {:}\".format(\n","        CLASS_MAP[preds[0].numpy()]\n","    )\n",")\n","ax.set_axis_off()\n","plt.show()"],"metadata":{"id":"8LDaI9QLGlkI"},"execution_count":null,"outputs":[]}]}